# %% [markdown]
# # 01. Data Exploration
# 
# The goal of this notebook is to explore and understand the datasets used in the fruit VQA project:
# 1.  **TLU-Fruit Dataset**: The custom agricultural dataset introduced in the paper.
# 2.  **COCO-QA Dataset**: A standard VQA dataset for comparison and evaluation.
# 
# We will look at basic statistics, analyze questions and answers, and display some sample data.

# %% [code]
import json
import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from collections import Counter
import numpy as np

# Plot settings
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (10, 6)

# %% [markdown]
# ## 1. Define Data Paths
# 
# **IMPORTANT:** Please update the following paths to match your data locations.

# %% [code]
# Assuming the directory structure as discussed:
# project_root/
# ├── data/
# │   ├── raw/
# │   │   ├── TLU-Fruit/
# │   │   │   ├── images/
# │   │   │   └── annotations_tlu_fruit.json # Rename if needed
# │   │   └── COCO-QA/
# │   │       ├── images/ # COCO images are usually in train2014, val2014
# │   │       └── annotations_coco_qa.json   # Rename if needed

BASE_DATA_PATH = os.path.join("..", "data", "raw") # Assuming this notebook is in the notebooks/ directory

# TLU-Fruit paths
TLU_FRUIT_ANNOTATIONS_PATH = os.path.join(BASE_DATA_PATH, "TLU-Fruit", "annotations_tlu_fruit.json")
TLU_FRUIT_IMAGES_DIR = os.path.join(BASE_DATA_PATH, "TLU-Fruit", "images")

# COCO-QA paths (COCO-QA typically uses images from MS COCO)
COCO_QA_ANNOTATIONS_PATH = os.path.join(BASE_DATA_PATH, "COCO-QA", "annotations_coco_qa.json")
# COCO_IMAGES_TRAIN_DIR = os.path.join(BASE_DATA_PATH, "COCO-QA", "train2014") # Or the directory containing corresponding COCO images
# COCO_IMAGES_VAL_DIR = os.path.join(BASE_DATA_PATH, "COCO-QA", "val2014")   # Or the directory containing corresponding COCO images
# For COCO-QA, image path management can be a bit more complex depending on how you downloaded it.
# In this notebook, we will focus on the annotations.

print(f"TLU-Fruit Annotations Path: {TLU_FRUIT_ANNOTATIONS_PATH}")
print(f"TLU-Fruit Images Dir: {TLU_FRUIT_IMAGES_DIR}")
print(f"COCO-QA Annotations Path: {COCO_QA_ANNOTATIONS_PATH}")

# %% [markdown]
# ## 2. Helper Functions

# %% [code]
def load_json_data(file_path):
    """Loads data from a JSON file."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"Successfully loaded data from: {file_path}")
        return data
    except FileNotFoundError:
        print(f"ERROR: File not found: {file_path}")
        return None
    except json.JSONDecodeError:
        print(f"ERROR: Could not decode JSON from file: {file_path}")
        return None

def display_image_from_path(image_path, title=""):
    """Displays an image from the given path."""
    try:
        img = Image.open(image_path)
        plt.imshow(img)
        plt.title(title if title else os.path.basename(image_path))
        plt.axis('off')
        plt.show()
    except FileNotFoundError:
        print(f"ERROR: Image not found at: {image_path}")

# %% [markdown]
# ## 3. TLU-Fruit Dataset Exploration
# 
# According to the paper:
# - 8,245 Question-Answer (QA) pairs
# - 2,053 images
# - Images captured in diverse settings.
# - Questions are categorized: ~65% relate directly to agricultural products, the rest are unrelated.

# %% [code]
tlu_fruit_data = load_json_data(TLU_FRUIT_ANNOTATIONS_PATH)

# %% [markdown]
# ### 3.1. TLU-Fruit Data Structure
# 
# We need to inspect the structure of `tlu_fruit_data`. Assuming it's a list of items, each containing information about a QA pair and its associated image.
# 
# Possible fields in each item (needs adjustment based on your actual JSON file):
# - `image_id` or `image_filename`
# - `question`
# - `answer`
# - `question_type` (e.g., 'agricultural', 'other') - based on the 65% description in the paper

# %% [code]
if tlu_fruit_data:
    print(f"TLU-Fruit data type: {type(tlu_fruit_data)}")
    if isinstance(tlu_fruit_data, list) and len(tlu_fruit_data) > 0:
        print(f"Number of QA items in TLU-Fruit: {len(tlu_fruit_data)}")
        print(f"Example of the first item: {tlu_fruit_data[0]}")
        
        # Convert to Pandas DataFrame for easier analysis
        tlu_fruit_df = pd.DataFrame(tlu_fruit_data)
        print("\nTLU-Fruit DataFrame (first 5 rows):")
        print(tlu_fruit_df.head())
    elif isinstance(tlu_fruit_data, dict):
        # Data might be organized differently, e.g., a dict with 'annotations', 'images' keys
        print("TLU-Fruit data is a dictionary. Main keys:")
        print(list(tlu_fruit_data.keys()))
        # You might need to adjust this part to extract the QA list
        # Example: if 'annotations' in tlu_fruit_data:
        #           tlu_fruit_df = pd.DataFrame(tlu_fruit_data['annotations'])
        #           print(tlu_fruit_df.head())
        #         else:
        #           print("Expected 'annotations' key not found.")
        # Since there's no actual file, this part is speculative
        tlu_fruit_df = None # Will need adjustment
        # Assuming a common structure: list of dicts for VQA
        if isinstance(tlu_fruit_data.get('annotations'), list): # Common assumption
             tlu_fruit_df = pd.DataFrame(tlu_fruit_data['annotations'])
        elif isinstance(tlu_fruit_data, list): # If it's a flat list of QAs
             tlu_fruit_df = pd.DataFrame(tlu_fruit_data)


if 'tlu_fruit_df' in locals() and tlu_fruit_df is not None:
    print("\nTLU-Fruit DataFrame Info:")
    tlu_fruit_df.info()
else:
    print("\nCould not create DataFrame from TLU-Fruit data. Please check the JSON file structure.")

# %% [markdown]
# ### 3.2. TLU-Fruit Basic Statistics

# %% [code]
if 'tlu_fruit_df' in locals() and tlu_fruit_df is not None and not tlu_fruit_df.empty:
    num_qa_pairs_tlu = len(tlu_fruit_df)
    # Assuming there's an 'image_id' or 'image_filename' column to count unique images
    image_id_col = 'image_id' if 'image_id' in tlu_fruit_df.columns else \
                   'image_filename' if 'image_filename' in tlu_fruit_df.columns else None

    if image_id_col:
        num_unique_images_tlu = tlu_fruit_df[image_id_col].nunique()
        avg_qa_per_image_tlu = num_qa_pairs_tlu / num_unique_images_tlu if num_unique_images_tlu > 0 else 0

        print(f"Number of QA pairs in TLU-Fruit (from DataFrame): {num_qa_pairs_tlu}")
        print(f"Number of unique images in TLU-Fruit (from DataFrame): {num_unique_images_tlu}")
        print(f"Average QA pairs per image: {avg_qa_per_image_tlu:.2f}")
    else:
        print("Could not find 'image_id' or 'image_filename' column to count unique images.")
        # According to the paper
        num_qa_pairs_paper = 8245
        num_images_paper = 2053
        print(f"\nAccording to the paper:")
        print(f"Number of QA pairs in TLU-Fruit: {num_qa_pairs_paper}")
        print(f"Number of images: {num_images_paper}")
        print(f"Average QA pairs per image (from paper): {num_qa_pairs_paper / num_images_paper:.2f}")

# %% [markdown]
# ### 3.3. TLU-Fruit Image Exploration (Sample)
# 
# Display a few sample images along with their corresponding QA pairs.
# This requires an `image_filename` (or similar) column in the DataFrame.

# %% [code]
if 'tlu_fruit_df' in locals() and tlu_fruit_df is not None and not tlu_fruit_df.empty:
    # Requires a column with the image filename, e.g., 'image_filename'
    # or 'image_id' from which the filename can be inferred.
    # Assuming the filename is stored in 'image_filename'.
    filename_col = 'image_filename' if 'image_filename' in tlu_fruit_df.columns else \
                   'file_name' if 'file_name' in tlu_fruit_df.columns else None # Some datasets use 'file_name'

    if filename_col:
        print("\nDisplaying sample images and QAs from TLU-Fruit:")
        sample_indices = tlu_fruit_df.sample(min(3, len(tlu_fruit_df))).index

        for idx in sample_indices:
            row = tlu_fruit_df.loc[idx]
            image_filename = row[filename_col]
            question = row.get('question', 'N/A')
            answer = row.get('answer', 'N/A')
            
            image_path = os.path.join(TLU_FRUIT_IMAGES_DIR, image_filename)
            
            print(f"\n--- Image: {image_filename} ---")
            print(f"Question: {question}")
            print(f"Answer: {answer}")
            display_image_from_path(image_path)
            plt.pause(0.1) # To allow plot to render if in a loop
    else:
        print("Could not find image filename column (e.g., 'image_filename' or 'file_name') in TLU-Fruit DataFrame.")

# %% [markdown]
# ### 3.4. TLU-Fruit Question Analysis

# %% [code]
if 'tlu_fruit_df' in locals() and tlu_fruit_df is not None and not tlu_fruit_df.empty and 'question' in tlu_fruit_df.columns:
    # Question length (number of words)
    tlu_fruit_df['question_length'] = tlu_fruit_df['question'].apply(lambda x: len(str(x).split()))
    
    plt.figure(figsize=(12, 6))
    sns.histplot(tlu_fruit_df['question_length'], bins=30, kde=True)
    plt.title('Distribution of Question Length (Number of Words) - TLU-Fruit')
    plt.xlabel('Number of words in question')
    plt.ylabel('Frequency')
    plt.show()
    
    print("\nStatistics for TLU-Fruit question length:")
    print(tlu_fruit_df['question_length'].describe())

    # Common question starting words
    tlu_fruit_df['question_start_word'] = tlu_fruit_df['question'].apply(lambda x: str(x).split()[0].lower() if len(str(x).split()) > 0 else "")
    
    common_start_words = tlu_fruit_df['question_start_word'].value_counts().head(15)
    plt.figure(figsize=(12, 7))
    common_start_words.plot(kind='bar')
    plt.title('Top 15 Most Common Question Starting Words - TLU-Fruit')
    plt.xlabel('Starting word')
    plt.ylabel('Count')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

    # Analyze question types (if 'question_type' column exists)
    # Paper states ~65% are agriculture-related.
    if 'question_type' in tlu_fruit_df.columns:
        question_type_counts = tlu_fruit_df['question_type'].value_counts(normalize=True) * 100
        print("\nDistribution of question types (%):")
        print(question_type_counts)
        
        plt.figure(figsize=(8, 8))
        question_type_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90)
        plt.title('Distribution of Question Types - TLU-Fruit')
        plt.ylabel('') # Remove y-axis label for pie chart
        plt.show()
    else:
        print("\n'question_type' column not found in TLU-Fruit data for direct analysis.")
        print("The paper indicates that approximately 65% of questions are agriculture-related.")

# %% [markdown]
# ### 3.5. TLU-Fruit Answer Analysis

# %% [code]
if 'tlu_fruit_df' in locals() and tlu_fruit_df is not None and not tlu_fruit_df.empty and 'answer' in tlu_fruit_df.columns:
    # Answer length (number of words)
    # Answers can be single words (yes/no, fruit name) or phrases.
    tlu_fruit_df['answer_length'] = tlu_fruit_df['answer'].apply(lambda x: len(str(x).split()))
    
    plt.figure(figsize=(12, 6))
    sns.histplot(tlu_fruit_df['answer_length'], bins=30, kde=True)
    plt.title('Distribution of Answer Length (Number of Words) - TLU-Fruit')
    plt.xlabel('Number of words in answer')
    plt.ylabel('Frequency')
    plt.show()

    print("\nStatistics for TLU-Fruit answer length:")
    print(tlu_fruit_df['answer_length'].describe())

    # Most common answers
    # Convert all answers to lowercase for consistent counting
    common_answers = tlu_fruit_df['answer'].astype(str).str.lower().value_counts().head(20)
    
    plt.figure(figsize=(12, 8))
    common_answers.plot(kind='bar')
    plt.title('Top 20 Most Common Answers (Lowercase) - TLU-Fruit')
    plt.xlabel('Answer')
    plt.ylabel('Count')
    plt.xticks(rotation=75, ha='right')
    plt.tight_layout()
    plt.show()
    
    # Check the number of "yes"/"no" answers
    yes_no_answers = tlu_fruit_df['answer'].astype(str).str.lower().isin(['yes', 'no'])
    print(f"\nPercentage of Yes/No answers: {yes_no_answers.mean()*100:.2f}%")

# %% [markdown]
# ## 4. COCO-QA Dataset Exploration
# 
# COCO-QA is a popular VQA dataset. We will perform some similar analyses, perhaps more briefly.

# %% [code]
coco_qa_data = load_json_data(COCO_QA_ANNOTATIONS_PATH)

# %% [markdown]
# ### 4.1. COCO-QA Data Structure
# 
# Similar to TLU-Fruit, we need to inspect the structure of `coco_qa_data`. Typically, COCO-QA is also a list of QA pairs.

# %% [code]
if coco_qa_data:
    print(f"COCO-QA data type: {type(coco_qa_data)}")
    if isinstance(coco_qa_data, list) and len(coco_qa_data) > 0:
        print(f"Number of QA items in COCO-QA: {len(coco_qa_data)}")
        print(f"Example of the first item: {coco_qa_data[0]}")
        
        coco_qa_df = pd.DataFrame(coco_qa_data)
        print("\nCOCO-QA DataFrame (first 5 rows):")
        print(coco_qa_df.head())
    elif isinstance(coco_qa_data, dict):
        print("COCO-QA data is a dictionary. Main keys:")
        print(list(coco_qa_data.keys()))
        # Assuming a common VQA structure: list of dicts
        if isinstance(coco_qa_data.get('annotations'), list): # Common assumption
             coco_qa_df = pd.DataFrame(coco_qa_data['annotations'])
        elif isinstance(coco_qa_data, list): # If it's a flat list of QAs
             coco_qa_df = pd.DataFrame(coco_qa_data)

if 'coco_qa_df' in locals() and coco_qa_df is not None:
    print("\nCOCO-QA DataFrame Info:")
    coco_qa_df.info()
else:
    print("\nCould not create DataFrame from COCO-QA data. Please check the JSON file structure.")

# %% [markdown]
# ### 4.2. COCO-QA Basic Statistics

# %% [code]
if 'coco_qa_df' in locals() and coco_qa_df is not None and not coco_qa_df.empty:
    num_qa_pairs_coco = len(coco_qa_df)
    image_id_col_coco = 'image_id' if 'image_id' in coco_qa_df.columns else \
                        'image_name' if 'image_name' in coco_qa_df.columns else \
                        'img_id' if 'img_id' in coco_qa_df.columns else None

    if image_id_col_coco:
        num_unique_images_coco = coco_qa_df[image_id_col_coco].nunique()
        avg_qa_per_image_coco = num_qa_pairs_coco / num_unique_images_coco if num_unique_images_coco > 0 else 0

        print(f"Number of QA pairs in COCO-QA (from DataFrame): {num_qa_pairs_coco}")
        print(f"Number of unique images in COCO-QA (from DataFrame): {num_unique_images_coco}")
        print(f"Average QA pairs per image: {avg_qa_per_image_coco:.2f}")
    else:
        print("Could not find 'image_id' (or similar) column to count unique images in COCO-QA.")
        print(f"Number of QA pairs in COCO-QA (from DataFrame): {num_qa_pairs_coco}")

# %% [markdown]
# ### 4.3. COCO-QA Question and Answer Analysis (Brief)

# %% [code]
if 'coco_qa_df' in locals() and coco_qa_df is not None and not coco_qa_df.empty:
    if 'question' in coco_qa_df.columns:
        coco_qa_df['question_length'] = coco_qa_df['question'].apply(lambda x: len(str(x).split()))
        plt.figure(figsize=(10, 5))
        sns.histplot(coco_qa_df['question_length'], bins=30, kde=True)
        plt.title('Distribution of Question Length - COCO-QA')
        plt.show()
        print("\nStatistics for COCO-QA question length:")
        print(coco_qa_df['question_length'].describe().loc[['mean', 'std', 'min', 'max']])

    if 'answer' in coco_qa_df.columns:
        # COCO-QA answers are typically single words
        common_answers_coco = coco_qa_df['answer'].astype(str).str.lower().value_counts().head(15)
        plt.figure(figsize=(10, 6))
        common_answers_coco.plot(kind='bar')
        plt.title('Top 15 Most Common Answers - COCO-QA')
        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.show()

# %% [markdown]
# ## 5. Summary and Next Steps
# 
# This notebook has provided an initial overview of the TLU-Fruit and COCO-QA datasets.
# 
# **Key findings (to be updated after running with actual data):**
# - **TLU-Fruit:**
#     - Number of QA samples and images.
#     - Characteristics of question and answer lengths.
#     - Common question types and answers, potentially showing a focus on the agricultural domain.
# - **COCO-QA:**
#     - Number of QA samples and images.
#     - Characteristics of question and answer lengths (often single-word answers).
# 
# **Possible next steps include:**
# - `02_data_preprocessing.ipynb`: Preprocess the data, including text tokenization, image processing (resizing, normalization, creating segmented/cropped versions as in the paper).
# - More detailed vocabulary construction.
# - Deeper analysis of the correlation between questions and image types (if this information is available).

# %% [code]
print("Basic data exploration complete!")